{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "\n",
    "So we will be conducting sentiment analysis to our semantic data gathered from Twitter and Reddit comments. We will use VADER to calculate polarity scores indicating the sentiment of the input text. VADER is a parsimonious rule-based model for sentiment analysis of social media text, perfect for our purpose. In this notebook we will access the data from the CSV files, clean the data, calculate the polarity score, add this to the CSV and store the new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "tweets_names_list = ['T_ada_march_18.csv', 'T_ada_april_18.csv', 'T_ada_may_18.csv', 'T_ada_june_18.csv', 'T_ada_july_18.csv', 'T_ada_august_18.csv',\\\n",
    "                  'T_ada_september_18.csv', 'T_ada_october_18.csv', 'T_ada_november_18.csv', 'T_ada_december_18.csv', 'T_ada_january_19.csv',\\\n",
    "                  'T_ada_february_19.csv', 'T_ada_march_19.csv', 'T_ada_april_19.csv', 'T_ada_may_19.csv', 'T_ada_june_19.csv', 'T_ada_july_19.csv',\\\n",
    "                  'T_ada_august_19.csv', 'T_ada_september_19.csv', 'T_ada_october_19.csv', 'T_ada_november_19.csv', 'T_ada_december_19.csv',\\\n",
    "                  'T_ada_january_20.csv', 'T_ada_febrauri_20.csv', 'T_ada_march_20.csv', 'T_ada_april_20.csv', 'T_ada_may_20.csv', 'T_ada_june_20.csv',\\\n",
    "                  'T_ada_july_20.csv', 'T_ada_august_20.csv', 'T_ada_september_20.csv', 'T_ada_october_20.csv', 'T_ada_november_20.csv',\\\n",
    "                  'T_ada_december_20.csv', 'T_ada_january_21.csv', 'T_ada_february_21.csv', 'T_ada_march_21.csv', 'T_ada_april_21.csv', 'T_ada_may_21.csv']\n",
    "reddit_names_list = ['R_ada_march_18.csv', 'R_ada_april_18.csv', 'R_ada_may_18.csv', 'R_ada_june_18.csv', 'R_ada_july_18.csv', 'R_ada_august_18.csv',\\\n",
    "                  'R_ada_september_18.csv', 'R_ada_october_18.csv', 'R_ada_november_18.csv', 'R_ada_december_18.csv','R_ada_january_19.csv',\\\n",
    "                  'R_ada_febrauri_19.csv', 'R_ada_march_19.csv', 'R_ada_april_19.csv', 'R_ada_may_19.csv', 'R_ada_june_19.csv', 'R_ada_july_19.csv',\\\n",
    "                  'R_ada_august_19.csv', 'R_ada_september_19.csv', 'R_ada_october_19.csv', 'R_ada_november_19.csv', 'R_ada_december_19.csv',\\\n",
    "                  'R_ada_january_20.csv', 'R_ada_febrauri_20.csv', 'R_ada_march_20.csv', 'R_ada_april_20.csv', 'R_ada_may_20.csv', 'R_ada_june_20.csv',\\\n",
    "                  'R_ada_july_20.csv', 'R_ada_august_20.csv', 'R_ada_september_20.csv', 'R_ada_october_20.csv', 'R_ada_november_20.csv',\\\n",
    "                  'R_ada_december_20.csv', 'R_ada_january_21.csv', 'R_ada_february_21.csv', 'R_ada_march_21.csv','R_ada_april_21.csv', 'R_ada_may_21.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "for doc in reddit_names_list:\n",
    "    df = pd.read_csv(doc)\n",
    "    text = df['body'].apply(lambda x: '' if len(x) < 10 else x)\n",
    "    for i, sentence in enumerate(text):\n",
    "        sentence = re.sub(r'@[A-Za-z0-9]+', \"\", sentence) # Removal of @mentions\n",
    "        sentence = re.sub(r'#', '', sentence) # Removal of #\n",
    "        sentence = re.sub(r'RT[\\s]+', '', sentence) # Removal of RT\n",
    "        sentence = re.sub(r'&amp?', '&', sentence) # Replacement of &amp; to &\n",
    "        sentence = re.sub(r'https?:\\/\\/\\S+', '', sentence) # Removal of hyperlinks\n",
    "        text[i] = sentence\n",
    "    df[['negative', 'neutral', 'positive', 'compound']] = text.apply(lambda body:pd.Series(analyzer.polarity_scores(body)))\n",
    "    df.to_csv(doc)\n",
    "    \n",
    "for doc in tweets_names_list:\n",
    "    df = pd.read_csv(doc)\n",
    "    text = df['content'].apply(lambda x: '' if len(x) < 10 else x)\n",
    "    for i, sentence in enumerate(text):\n",
    "        sentence = re.sub(r'@[A-Za-z0-9]+', \"\", sentence) # Removal of @mentions\n",
    "        sentence = re.sub(r'#', '', sentence) # Removal of #\n",
    "        sentence = re.sub(r'RT[\\s]+', '', sentence) # Removal of RT\n",
    "        sentence = re.sub(r'&amp;', '&', sentence) # Replacement of &amp; to &\n",
    "        sentence = re.sub(r'https?:\\/\\/\\S+', '', sentence) # Removal of hyperlinks\n",
    "        text[i] = sentence\n",
    "    df[['negative', 'neutral', 'positive', 'compound']] = text.apply(lambda body:pd.Series(analyzer.polarity_scores(body)))\n",
    "    df.to_csv(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
